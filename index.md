---
layout: home
profile_picture:
  src: /assets/img/sattar_pic.jpg
  alt: sattar vakili
---
<h3><strong>Principal AI Research Manager
  
@ <a href="https://i.mediatek.com/mediatekresearch" target="_blank" rel="noopener">MediaTek Research</a></strong></h3>



<h4>sv388 [AT] cornell [DOT] edu</h4>

<h4>sattar.vakili [AT] mtkresearch [DOT] com</h4>









# Research Interests

<ul>
  <li> Machine learning and artificial intelligence</li>
  <li> Sequential decision making, bandit and RL</li>
  <li> Kernel methods, Gaussian processes and Bayesian optimisation</li>
  <li> Diffusion models</li>
</ul>

<span style="color:white">Machine Learning, Bandit, Reinforcement learning, kernel methods, Google Scholar, LinkedIn, Cornell, MediaTek,  </span>

# Latest
<ul>
  <li><strong>January 2025: </strong><a href="https://openreview.net/forum?id=DgbY2CuyhW" target="_blank" rel="noopener">Near-Optimal Sample Complexity in Reward-Free Reinforcement Learning</a> is accepted at <strong>AISTATS 2025</strong>.</li>
  <li><strong>October 2024: </strong><a href="https://arxiv.org/abs/2410.23498" target="_blank" rel="noopener">Kernel-Based Function Approximation for Average Reward Reinforcement Learning: An Optimist No-Regret Algorithm</a> is accepted at <strong>NeurIPS 2024</strong>.</li>
  <li><strong>October 2024: </strong><a href="https://arxiv.org/abs/2302.08436" target="_blank" rel="noopener">Trieste: Efficiently Exploring The Depths of Black-box Functions with TensorFlow</a> is accepted at <strong>NeurIPS 2024</strong> Workshop on Bayesian Decision-making and Uncertainty.</li>
  <li><strong>September 2024:</strong> <a href="https://arxiv.org/abs/2310.01609" target="_blank" rel="noopener">Adversarial Contextual Bandits Go Kernelized</a> will be presented at European Workshop on Reinforcement Learning (EWRL 2024).</li>
  <li><strong>September 2024:</strong> <a href="https://arxiv.org/abs/2410.23498" target="_blank" rel="noopener">Kernel-Based Function Approximation for Average Reward Reinforcement Learning: An Optimist No-Regret Algorithm</a> will be presented at European Workshop on Reinforcement Learning (EWRL 2024).</li>
  <li><strong>July 2024: </strong> Giving a tutorial on <strong><a href="https://www.auai.org/uai2024/tutorials" target="_blank" rel="noopener">Recent Advances of Statistical Reinforcement Learning</a></strong> at Uncertainty in Artificial Intelligence (UAI) 2024, July 15th in Barcelona. <strong>[<a href="assets
/UAI2024_RL_tutorial.pdf" target="_blank" rel="noopener">Download the slides here</a>].</strong> </li>
  <li> <strong>June 2024:</strong> Involved in organizing <strong><a href="https://www.icml-meetup-london.info" target="_blank" rel="noopener">a local ICML meetup on July 12th in London</a></strong>. A great opportunity to present your work, learn, and grow your network.</li>
  <li><strong>June 2024: </strong><a href="https://arxiv.org/abs/2406.15250" target="_blank" rel="noopener">Open Problem: Order Optimal Regret Bounds for Kernel-Based Reinforcement Learning</a> is accepted at <strong>COLT 2024</strong>.</li>
  <li><strong>June 2024: </strong><a href="https://openreview.net/pdf?id=QTt2xJI8vk" target="_blank" rel="noopener">Reward-Free Kernel-Based Reinforcement Learning</a> is accepted at <strong>ICML 2024</strong>.</li>
  <li><strong>June 2024: </strong><a class="gsc_oci_title_link" href="https://arxiv.org/abs/2310.15351" target="_blank" rel="noopener" data-clk="hl=en&amp;sa=T&amp;ei=hBd2ZMqBNJaay9YP8PScyAs">Random Exploration in Bayesian Optimization: Order-Optimal Regret and Computational Efficiency</a> is accepted at <strong>ICML 2024</strong>.</li>
  <li><strong>April 2024: </strong> Giving a tutorial on <a href="https://www.auai.org/uai2024/tutorials" target="_blank" rel="noopener">Recent Advances of Statistical Reinforcement Learning</a> at Uncertainty in Artificial Intelligence (UAI) 2024, July 15th in Barcelona.</li>
  <li><strong>December 2023: </strong><a href="https://arxiv.org/abs/2312.09674" target="_blank" rel="noopener">Optimal Regret Bounds for Collaborative Learning in Bandits</a> is accepted at Algorithmic Learning Theory (ALT) 2024.</li>
  <li><strong>December 2023: </strong><a href="https://arxiv.org/abs/2310.01609" target="_blank" rel="noopener">Adversarial Contextual Bandits Go Kernelized</a> is accepted at Algorithmic Learning Theory (ALT) 2024.</li>
  <li><strong>December 2023: </strong> Presenting <a href="https://arxiv.org/abs/2306.07745" target="_blank" rel="noopener">our NeurIPS paper</a> at <a href="https://www.neuripsmeetupcambridge.info/home" target="_blank" rel="noopener">local meetup</a>, Cambrdige University, Dec 8th. </li>
  <li><strong>October 2023: </strong><a href="https://arxiv.org/abs/2207.07948" target="_blank" rel="noopener">Collaborative Learning in Kernel-based Bandits for Distributed Users</a> is accepted at IEEE Transactions on Signal Processing.</li>
  <li><strong>October 2023: </strong> Giving a talk at the <a href="https://team.inria.fr/scool/" target="_blank" rel="noopener">Inria Scool</a> seminar series at University of Lille.</li>
  <li><strong>October 2023: </strong><a href="https://arxiv.org/abs/2310.01609" target="_blank" rel="noopener">Adversarial Contextual Bandits Go Kernelized</a> is available on arXiv.</li>
  <li><strong>September 2023: </strong><a href="https://arxiv.org/abs/2306.07745" target="_blank" rel="noopener">Kernelized Reinforcement Learning with Order Optimal Regret Bounds</a> is accepted at <strong>NeurIPS 2023</strong>.</li>
  <li><strong>August 2023: </strong><a href="https://arxiv.org/abs/2308.05583" target="_blank" rel="noopener">Generative Diffusion Models for Radio Wireless Channel Modelling and Sampling</a> is accepted at <a href="https://globecom2023.ieee-globecom.org/" target="_blank" rel="noopener">GLOBECOM 2023</a>.</li>
 	<li><strong>August 2023: </strong><a href="https://arxiv.org/abs/2306.07745" target="_blank" rel="noopener">Kernelized Reinforcement Learning with Order Optimal Regret Bounds</a> is accepted at <a href="https://ewrl.wordpress.com/ewrl16-2023/" target="_blank" rel="noopener">EWRL 2023</a>.</li>
  <li><strong>August 2023: </strong> Check out <a href="https://proceedings.mlr.press/v195/lattimore23b.html" target="_blank" rel="noopener">Tor Lattimore's response</a> to the <a href="https://proceedings.mlr.press/v134/open-problem-vakili21a.html" target="_blank" rel="noopener">open problem</a> on online confidence intervals for RKHS elemets.</li>
 	<li><strong>July 2023:</strong> Giving an <a href="https://www.youtube.com/watch?v=lHqe8oa2VWU&amp;ab_channel=HadiAmini" target="_blank" rel="noopener">online lecture</a> at FeDucation seminar series (Florida International University).</li>
 	<li><strong>June 2023:</strong> Giving a <a href="https://ucl-ellis.github.io/dm_csml_seminars/2023-06-23-Vakili/" target="_blank" rel="noopener">seminar</a> on <a href="https://arxiv.org/pdf/2306.07745.pdf">kernel-based reinforcement learning</a> at Deepmind/Ellis CSML seminar series.</li>
 	<li><strong>June 2023:</strong> Presenting <a href="https://arxiv.org/abs/2109.06099" target="_blank" rel="noopener">Information Gain and Uniform Generalization Bounds for Neural Kernel Models</a> at ISIT 2023 , Taipei.</li>
 	<li><strong>May 2023:</strong> Giving an invited talk on kernel-based RL at the <a href="https://www.ucl.ac.uk/ai-centre/lsit-2023-seventh-london-symposium-information-theory">London Symposium on Information Theory</a></li>
 	<li><strong>April 2023:</strong> "<a class="gsc_a_at" href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=N9xs8w0AAAAJ&amp;sortby=pubdate&amp;citation_for_view=N9xs8w0AAAAJ:iH-uZ7U-co4C" target="_blank" rel="noopener">Delayed Feedback in Kernel Bandits</a>" is accepted at <strong>ICML 2023</strong>.</li>
 	<li><strong>April 2023: </strong>"<a class="gsc_oci_title_link" href="https://arxiv.org/abs/2206.00099" target="_blank" rel="noopener" data-clk="hl=en&amp;sa=T&amp;ei=hBd2ZMqBNJaay9YP8PScyAs">Provably and Practically Efficient Neural Contextual Bandits</a>" is accepted at <strong>ICML 2023</strong>.</li>
 	<li><strong>April 2023: </strong>"<a href="https://arxiv.org/abs/2306.00501" target="_blank" rel="noopener">Image generation with shortest path diffusion</a>" is accepted at <strong>ICML 2023</strong>.</li>
 	<li><strong>Feburary 2023: </strong>"<a href="https://arxiv.org/abs/2302.00392" target="_blank" rel="noopener">Delayed Feedback in Kernel Bandits</a>" is available on arXiv.</li>
 	<li><strong>January 2023: </strong>"<a href="https://arxiv.org/abs/2302.00727" target="_blank" rel="noopener">Sample Complexity of Kernel-Based Q-Learning</a>" is accepted at <strong>AISTATS 2023.</strong></li>
 	<li><strong>January 2023: </strong>"<a href="https://openreview.net/forum?id=c9lAOPvQHS" target="_blank" rel="noopener">Fisher-Legendre (FishLeg) optimization of deep neural networks</a>" is accepted at <strong>ICLR 2023.</strong></li>
 	<li><strong>December 2022: </strong>Presenting "<a href="https://opt-ml.org/papers/2022/paper26.pdf" target="_blank" rel="noopener">Gradient Descent: Robustness to Adversarial Corruption</a>" at OPT2022 workshop at <strong>NeurIPS 2022</strong>, New Orleans.</li>
 	<li><strong>October 2022:</strong> "<a href="https://openreview.net/forum?id=2xfJ26BuFP" target="_blank" rel="noopener">Near-Optimal Collaborative Learning in Bandits</a>" has been designated as an <span class="il"><strong>Oral</strong> presentation</span>  at <strong>NeurIPS 2022. </strong></li>
 	<li><strong>July 2022:</strong> Presenting an <a href="https://arxiv.org/abs/2002.05096" target="_blank" rel="noopener">open problem</a> on noise-free kernel-based bandit at <strong>COLT 2022</strong>, London.</li>
 	<li><strong>May 2022: </strong>"<a href="https://arxiv.org/abs/2206.00099" target="_blank" rel="noopener">Provably and Practically Efficient Neural Contextual Bandits</a>" is available on arXiv.</li>
 	<li><strong>May 2022: </strong>"<a href="https://arxiv.org/abs/2206.00121" target="_blank" rel="noopener">Near-Optimal Collaborative Learning in Bandits</a>" is available on arXiv.</li>
 	<li><strong>May 2022: </strong>"<a href="https://proceedings.mlr.press/v162/vakili22a.html" target="_blank" rel="noopener">Improved Convergence Rates for Sparse Approximation Methods in Kernel-Based Learning</a>" is accepted at <strong>ICML 2022 </strong>for a<strong> Spotlight </strong>presentation.</li>
 	<li><strong>October 2021:  </strong>"<a href="https://papers.nips.cc/paper/2021/hash/2c7f9ccb5a39073e24babc3a4cb45e60-Abstract.html" target="_blank" rel="noopener">Scalable Thompson Sampling using Sparse Gaussian Process Models</a>" is accepted at <strong>NeurIPS 2021.</strong></li>
 	<li><strong>October 2021:  </strong>"<a href="https://papers.nips.cc/paper/2021/hash/f19fec2f129fbdba76493451275c883a-Abstract.html" target="_blank" rel="noopener">A Domain-Shrinking based Bayesian Optimization Algorithm with Order-Optimal Regret Performance</a>" is accepted at <strong>NeurIPS 2021.</strong></li>
 	<li><strong>October 2021:  </strong>"<a href="https://papers.nips.cc/paper/2021/hash/b1300291698eadedb559786c809cc592-Abstract.html" target="_blank" rel="noopener">Optimal Order Simple Regret for Gaussian Process Bandits</a>" is accepted at <strong>NeurIPS 2021.</strong></li>
 	<li><strong>August 2021: </strong>Moderating the "Bandits, RL and Control" session at <strong>COLT 2021</strong>.</li>
 	<li><strong>August 2021: </strong>Presenting "<a href="https://proceedings.mlr.press/v134/open-problem-vakili21a.html">Tight Online Confidence Intervals for RKHS Elements</a>" at <strong>COLT 2021</strong>.</li>
 	<li><strong>January 2021: </strong>"<span class=" aw5Odc"><a class="XqQF9c" href="https://proceedings.mlr.press/v130/vakili21a.html" target="_blank" rel="noopener">On Information Gain and Regret Bounds in Gaussian Process Bandits</a></span>" is accepted to be presented at <span class=" aw5Odc"><strong>AIStats 2021</strong></span>.</li>
</ul>



